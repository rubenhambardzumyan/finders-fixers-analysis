{"transcript":"# XO Check-in\n\n## Topics\n\n\n## Transcript\n\n[Aryuth Ekkul] (2025-10-22T08:32:09.362Z)\nHow are you? Fine, fine. How are you doing? Well, good, I think. Can be better? Yeah, it can be better. Hey, Jasger.\n\n[UNKNOWN_SPEAKER] (2025-10-22T08:32:28.088Z)\nHey, guys.\n\n[Artem Melnikov] (2025-10-22T08:32:30.389Z)\nHow are you doing?\n\n[UNKNOWN_SPEAKER] (2025-10-22T08:32:33.690Z)\nHow are you guys doing?\n\n[Artem Melnikov] (2025-10-22T08:32:37.191Z)\nYeah, just looking into the, you know, shitty legacy Salesforce code. It's fine. Yeah, yeah, yeah.\n\n[Rezgar Cadro] (2025-10-22T08:32:48.074Z)\nI think we all are. Thank god for AI, for reverse engineering stuff. I have no idea how I will figure stuff out without it. Hi, hi, everyone.\n\n[Anirudh Bhardwaj] (2025-10-22T08:33:11.733Z)\nNice haircut, Ariut. Hi, hi, there goes.\n\n[Dragos Nuta] (2025-10-22T08:33:29.149Z)\nOh, OK. You got some comments from Margie. And she has some there, like, why five minutes? Actually, after reading the tag, I I was wondering whether that's an artificial precision or you're just trying to make numbers fit. How did you end up doing that?\n\n[Aryuth Ekkul] (2025-10-22T08:33:56.193Z)\nThat came from the prompt. I just downloaded some videos there, rubrics, the human grading, and then gave me the questions. I even didn't change anything in the prompt.\n\n[UNKNOWN_SPEAKER] (2025-10-22T08:34:07.736Z)\nYou didn't what?\n\n[Aryuth Ekkul] (2025-10-22T08:34:10.677Z)\nI didn't touch the prompt itself. So the prompt that you see, accord from DB9, basically.\n\n[Dragos Nuta] (2025-10-22T08:34:21.230Z)\nSo the thresholds and one-minute talking, 25% in the frame, those were ALM suggestions that you accepted as such?\n\n[Aryuth Ekkul] (2025-10-22T08:34:33.695Z)\nSo yeah, this is like, I think this is, we can see this as a baseline, right? And then we have to test more with more test samples, see the accuracy, and then we can adjust and add or remove questions.\n\n[Dragos Nuta] (2025-10-22T08:34:48.969Z)\nI think that any time we end up with, for me in general, I can see them as red flags, things such as numbers in the rule, this type of thing. You need to have been active for at least one minute and 45 seconds. Why not one in 40? I'm just making up some number, right? Or it needs to be at least two rules out of four. Those are signs that we might be doing something not necessarily aligned with how people are doing.\n\n And that's where we need to talk to the SM. So we're doing that. We're going to talk to the, I don't know if she replied on any of my comments, because I basically asked her, OK, you explain how you're grading, and we'll take it from there. But definitely, those are easy to become hit or miss, right? The pressure of things such as it needs to be 1.45 minutes. Otherwise, it's a reject or something like that.\n\n They can easily turn into hit or miss.\n\n[Rezgar Cadro] (2025-10-22T08:35:51.213Z)\nYeah, but the results will be better once we get more sample size, more samples.\n\n[Dragos Nuta] (2025-10-22T08:35:55.794Z)\nThat was my suggestion to our youth. Increase it to like 50. And even then, I'm not sure. I think I remember. Remember three, four years ago, CNU, I don't know, it's a research division somewhere in Trilogy, whatever. They have their own way of working, but smart kids straight out of college that did a lot of research doing POCs, right? And then they tried to build a predictor for the candidate. They reach into the interview based on initial application information in order to have our outbound people out to them and convince them to finish this and whatnot.\n\n And it's like the classic model problem, like when they come back with the features that are influenced, it doesn't make any fucking sense. In the real world, that will never have any meaning. Like, you know, university graduated whenever. Like, really? Like, that's the new rule? To call people only if that's the case? Doesn't make any sense, right? And the same applies in my mind here. When I'm seeing rules that have some specific numbers there.\n\n I'm like, ah, that's not causality. It's just a random correlation, right? But there's no relationship or actual dependency or causality, right? It's come to work like that.\n\n[Aryuth Ekkul] (2025-10-22T08:37:16.387Z)\nYeah, I think this is like we're trying to reverse engineer how the human creating, create it.\n\n[Dragos Nuta] (2025-10-22T08:37:25.730Z)\nNo, of course, of course. And I understand the challenge. And let's discuss about the ATDs. Don't stay away from artificial precision. That's a principle that I would apply. Okay, everyone will say at least one in five minutes. Don't take artificial precision unless you have very clear arguments. Otherwise, stay into things that are more objective. Like, okay, so you want presence through most of the video.\n\n Okay, let's model it like that because, I don't know, I understand it won't be precise, but then again, I don't necessarily believe your number either, right? Or turn that into a prompt and list your doubts of the rules and they get the SME field, I'm like, hey, I don't know, this one seems too bad to correlate, but I don't know if that just happens to a correlation or that actually there's a cause effect there, right?\n\n Those are my best suggestions. Like reverse engineering and kind of keeping the blinders might easily go in a very, very, very wrong place. And I'm not saying we're there. I'm saying that I'm happy we increased the sample fat, and we need to increase the explainability of your model, right? Let's say so, right? Need to make your features kind of like not to learn artificial precision and you need to explain how you came with those and just make sure that we...\n\n I see there's a rubric, like, hey, I wrote this. Here's what I wrote. Please provide your input. Thumbs up, thumbs down, no, do something else. Like, make it super clear, not Read the prompt. By the way, that's another thing that why I like Brainless more than prompts. Like, prompt is a story. It's almost like saying, can you please Read this novel? And tell me if you like it. If you like the main idea, actually that's, if you like the main idea, no, can't you just tell me the main idea, I'll tell you if I like it.\n\n Having to Read the novel, like it's the same prompt versus like brainless. Same is here, like you don't want necessarily people to Read a prompt, you want them to align with your key ITTs.\n\n[Anirudh Bhardwaj] (2025-10-22T08:39:12.420Z)\nI think you're- Sorry. Sorry, sorry. So to get into a deterministic state for this particular POC, So one is obviously to increase the number of sample set that we have. But how should we plan? So we would eventually have to plan the goal life for this, right? So should we wait for Himanshi to give us the exact SME understanding that she has to help us write the prompt? Or would we want to give us...\n\n\n\n[Dragos Nuta] (2025-10-22T08:39:45.169Z)\nI'll do the following things. First, let's talk about the outcome. I'll keep stressing because unless you figure out what you want to achieve, you might be doing the wrong work. And I stress that it is valuable to build a low-bar filter. It is valuable to tell what definitely you don't have to look at Himanshi or whomever. Got it. Don't try to over-optimize for the perfect case. If you're not ready, it's clear we're not ready.\n\n And if you can get a small win in the sense of these guys will never pass, ship that. I am going to start from there. And then if you start from there, then the next question is, how do we increase explainability of our model? Which basically is, I've taken your things, I've broken down to this. This is why, because the LLM consider that the reason to include that is because, right? It's almost like a brainless style thing.\n\n Because the LLMs consider that the standard in the world, or the experts, or whatever it is, the reasoning is that this is one of the elements that create engagement, or that creates whatever. Explain, you're not the expert, but put the reasoning or why that item end up in your bar. Remove artificial precision, it will get you nowhere. I would remove it now, even if it hurts your accuracy, because it's fake accuracy.\n\n It happens that those that you had had 1.45. And then you have two paths. One path is, now that you have a model that is at least three of artificial precision, you'll see what your accuracy is without trying to pull knobs that teach random. And with those knobs, you'll see if you're rejecting people that shouldn't be rejected or not. And if you're like, you know what? My filter will not fully grade.\n\n But you know what? I will reject 80% of the people that you'd reject. So you'll end up rejecting some. 10% accepting 90%, which I think is a great trade-off. How about you do that? It will reduce your grading time. It will reduce your video watching time by 80%. That's absolutely amazing. That's an offer you can't refuse. So that's my suggestion.\n\n[UNKNOWN_SPEAKER] (2025-10-22T08:42:00.869Z)\nMakes sense.\n\n[Dragos Nuta] (2025-10-22T08:42:01.429Z)\nI would clean up that rubric, reassess, increase to 50%, increase video explainability, put the reasoning behind that. Even if the reasoning is like, Jamie, said that and I just trust on it without trying to push on Gemini why do that like remember when I was I was asking you like how about if you try to decompose the rule as thinking from the angle of a teacher versus a social media person versus a panel like a because I'm sure that the LLM when you're telling the engagement story it will it can think from very from many angles and I know that in yes social media versus corporate communication versus, I don't know, video.\n\n Engaging is very different versus an actor, versus, I don't know, influencers. There is a different definition of engagement. When I'm looking at that rubric, I see subjectivity. I see 20% subjectivity and 80% subjectivity, right? So that's what I suggested. Ask the LLM to do this from all angles. You can put it side by side, and maybe you'll start seeing some patterns, such as, oh, it's like, ask the LLM to contact so that you can put the anti-patterns into the engagement.\n\n Your prompt should also probably come. I can't emphasize on that. I don't know. These are things I would try. But anyway, long monologue. Increase size. Explain clearly why you have those things. Remove artificial precision. Test again. And come up with a message that says, here's how I'll apply these thresholds so that on a sizable sample set that covers rejected, accept, and all kinds of things, I'm telling you that I have a zero or right near zero false negative, false negative rate.\n\n And I don't care about the false positive in this, in this stage that will get improved as they provide feedback. And once you do that, the next question is, can we use video ask?\n\n[Aryuth Ekkul] (2025-10-22T08:44:09.887Z)\nOkay, so let's create a ticket and then let's work on it. This is more important than Serban copying his thinking.\n\n[UNKNOWN_SPEAKER] (2025-10-22T08:44:21.711Z)\nSerban what?\n\n[Aryuth Ekkul] (2025-10-22T08:44:22.971Z)\nThe plagiarism.\n\n[Dragos Nuta] (2025-10-22T08:44:29.173Z)\nI'd like to not leave things half done. I feel like you're not very far from cleaning up your rubric. And running on a larger data set, which will tell you where you are. Once you know where you are, look at the number. Whether you jump on video ask or not immediately, I don't know what to say.\n\n[Aryuth Ekkul] (2025-10-22T08:44:52.480Z)\nAnd Anirudh, can you help create a ticket for this?\n\n[Anirudh Bhardwaj] (2025-10-22T08:44:56.422Z)\nYeah, yeah.\n\n[Anirudh Bhardwaj] (2025-10-22T08:44:57.423Z)\nAnd I learned by the sample test data as well. That's there on the Salesforce.\n\n[Dragos Nuta] (2025-10-22T08:45:04.507Z)\nThere are some interesting comments there, saying, like, why use that? Because what if the people do that? Like, what if they're static? I think you should go through those comments. So when you pick samples, you would pick on some of her, or some of her, let's say, concerns of what can create a false negative. Because that's what you're looking for. Reduce the false negative rate.\n\n[Anirudh Bhardwaj] (2025-10-22T08:45:45.184Z)\nShould we at some point of time maybe not right now because for this POC and for this I think this version of our release we are clear that we'll focus to minimize false negatives while removing those numbers that we have in the system but eventually should we expect some brain lift from the SMEs in the longer run, maybe by the end of the quarter or maybe next quarter, so that we can directly...\n\n[Dragos Nuta] (2025-10-22T08:46:10.424Z)\nYou can actually platform chat and get Heather slash Tristan to work on that. I think that you can hone on the initial statement on what's valuable. I don't think that us ourselves can go to 100% accuracy, I mean, like full grading. I think that ourselves alone can do min-par. And yes, we'll need either to work with the SME or the SME to work alone to get to high accuracy. That's why I'm trying to pick a target that you guys have a chance at.\n\n Mean bar grading.\n\n[Anirudh Bhardwaj] (2025-10-22T08:46:42.249Z)\nMakes sense. Makes sense.\n\n[Dragos Nuta] (2025-10-22T08:46:46.192Z)\nAnd in my mind, a lot of this work is clock time, because you just have to let LMs. I made this logical difference between work time and clock time. Work time means I'm actually busy. Clock time, I just waiting for time to pass. I think a lot of your work will be clocked time, because you'll probably now have to let the LLM clean up your rubric, have to let it run on, I don't know, 50, 60 videos. So it will be a lot of waiting time.\n\n But in terms of probably wrapping up everything, I'm thinking that with one full day of actual work, not calendar work, I mean, like one full day of actual work, you'll probably have a very clear view of how far you can go and what's your false negative, false positive. What's your truth, right? About your confusion matrix, sorry. And don't try to overly improve it. Just start by posting it. Here's where we are.\n\n The sample set is representative. It's not biased in one place or another. Here's where we are as a confusion matrix. And then we will make a decision in that point. And I'm thinking that that alone can That means that this week you'll have the final results. Is that feasible? Or Monday, but as I said, I think it's a lot of clock time more than work time. On video ask, do you know, Artem, what was the time limit?\n\n Do you remember?\n\n[Artem Melnikov] (2025-10-22T08:48:14.184Z)\nI think we discarded it was five minutes last time we checked.\n\n[Dragos Nuta] (2025-10-22T08:48:18.126Z)\nWhich is the same as this one, right?\n\n[Artem Melnikov] (2025-10-22T08:48:22.188Z)\nYou mean the... I'm an old man. I forget.\n\n[Dragos Nuta] (2025-10-22T08:48:33.000Z)\nI don't have the beard that Rezgar has, but I'm still old. Nor his background. It's fake, right? Because otherwise I'll feel very bad. Not the beard, though. Yeah, the beard is not fake. I can imagine that. If I remember correctly, they would put the video in S3, send us a webhook. So I think that one I have this machinery that does the grading, Arius. Once you know that I can get a video and grade, hooking it into VideoASK will not be like rocket science, right?\n\n Basically, I think we'll deliver a video grading for VideoASK feature. So your application step needs to be based on VideoASK, and then your prompts will actually use the prompts in the AI grading, right, will actually use speedo assessing. I think that's how we're going to think about this feature. So I was just wondering, the final result, do we want to feed?\n\n[Rezgar Cadro] (2025-10-22T08:49:38.264Z)\nSo we just feed the video to the LLM and it does the grading, or does the LLM come up with a bunch of questions that are stored somewhere in the pipeline, in the configuration, and then we have the SME review them, and then ask those questions to the LLM while grading.\n\n[Dragos Nuta] (2025-10-22T08:50:09.495Z)\nNo, no, no. This is the same pattern as AI grading. We start with the rubric, and what Ayut is doing now, he's building the rubric for this particular assessment. At some point, we'll get to the point where that rubric either serves as a good mean bar, which is like the, I can't imagine us not doing that, or serves as the actual grading rubric. So once we have that, we'll use video ask to run the assessment.\n\n We'll get the webhook, which already stores the data in the system when the finished submission is done. And we'll take our grading using the rules that are stored in Salesforce, right? The ones that are created put them as rules. Now, will it use the same AI grading mechanism we have now in place, or will it be a different, I don't know, code base or plugin? I don't have a strong view. I'm just saying, I don't know.\n\n For example, scope simplification question. Do I have to support a mix of responses to Google Docs and VDO? In the current version is only VDO. You can't, you won't get and VDO and text and Google Docs and have an and grade everything together, right? Simplifying decision. It only works with video. You can branch out and say provider is video-less, then I'm going to trigger this workflow of grading.\n\n Provider is not video-less, then I'll trigger whatever we've built already.\n\n[Anirudh Bhardwaj] (2025-10-22T08:51:36.407Z)\nRagnos, one more thing. So the videos that get uploaded for this assessment, they are either on YouTube or Loom, right? And Himanshi, so the current process, goes on that link and then evaluate this. You will evaluate that. So we are not planning to automate that piece where we download the video from the YouTube link and the loom.\n\n[Dragos Nuta] (2025-10-22T08:51:57.475Z)\nLook, look at Vitoask. Vitoask is on a, it's a platform where you ask people to record the video and they send it back to you. That's what it is. We don't have to support YouTube and whatnot because it's just like a survey monkey, but the output is video. One or more videos. Even paths such as, if you press something, then record the video. If not, record something else. I think it was like a, right?\n\n Or am I wrong? I think it had a workflow or something like that. We will probably use the simple thing, which is, here are the instructions, go record the video, and I'll get the webhook when done. And that will give us, I think, an S3 link. I'm fairly sure it was an S3 pre-signed URL or something, right?\n\n[Artem Melnikov] (2025-10-22T08:52:42.885Z)\nbut they were giving the video link.\n\n[Dragos Nuta] (2025-10-22T08:52:45.267Z)\nYeah, it's a kid's semester link. So they're giving us a semester link, and then we can just grade from there.\n\n[Anirudh Bhardwaj] (2025-10-22T08:52:50.751Z)\nSo we will replace the existing process of recording it anywhere with VideoASK and then basically integrate VideoASK with AI video grading.\n\n[Dragos Nuta] (2025-10-22T08:53:04.062Z)\nWe'll have to redefine the application step, which, for example, will beg the question of how do you deliver the instructions to the user through VDOAS, because each platform has some peculiarities. Maybe I remember VDOAS, you cannot have a wall of text. Again, as I said, I think we'll just have to sort out and tell the hiring manager, here's how your new test experience will look like, and we're comfortable with it, streamlined enough.\n\n\n\n[Artem Melnikov] (2025-10-22T08:53:35.279Z)\nproject okay um so what's with ai grading so I mean like yeah there are kind of like so the there is I guess the situation in relation to that huge thread uh particularly is that well the switch from the old system to the new is not just as simple as changing the, you know, the drop down thing. The reason for that is because the new age integrating, it is, it just kind of has been created as a separate thing so that we can later deprecate the old stuff.\n\n We can make like the, we can say like, okay, yeah, sure. You are too lazy to like put one field in your prompt and say like, okay, assign the score, the 10 score points to the candidate if everything is good, right? But you want to use that legacy AI score field separately in the Salesforce, you already have it set. Yeah, you are too lazy to put that into the prompt. We can support that, but that would mean we would not be able later to duplicate the old style because, well, we will integrate it in the new approach, right?\n\n So my...\n\n[Dragos Nuta] (2025-10-22T08:54:52.377Z)\nOne of the problems, like one by one, it was a long conversation. One problem is that you need to be explicit about what to do. You need to install the agent, set the score, and that's like define the Is that the biggest problem they have?\n\n[Artem Melnikov] (2025-10-22T08:55:07.038Z)\nWell, there are two problems. The one is the problem that is around this explicit definition of what is the expected output, because right now we are basically having three possible outcomes of the grading instead of just one. Previously, it was always pass-fail. Now it can be pass-fail or some kind of score, or it can be the manual grading request. So that's why they need to be explicit in the prompt, in the grading rule.\n\n\n\n[Dragos Nuta] (2025-10-22T08:55:36.615Z)\nI think that's doable. I'm not worried about that. Even if we do it, whatever. It can be our biggest misunderstanding, but that's solvable.\n\n[Artem Melnikov] (2025-10-22T08:55:47.280Z)\nSo for what I know, Tristan, well, I think he understood it pretty fast. And I think he's pretty, at least I got some like minor bug reports from him, but I think he's pretty happy with how his, like, transition pipelines now work with the iGrading V2. So that means it's a doable task to transition. It's just you need to put a bit more work into it. So that is the first problem. The second problem right now is kind of about, overall, I would say it's about throttling and the API calls and the token limits and stuff.\n\n So, well, we're hitting those limits. That's kind of the core situation. So for example, there is one situation where Tristan was hitting like the, I think, upper bound of the token size count because he was putting too much context. So that is, well, we cannot really bypass that, but we can at least be better in delivering that feedback. That is something that I will improve.\n\n[Dragos Nuta] (2025-10-22T08:56:49.328Z)\nSorry, so the assessment is too large or the prompts are too large?\n\n[Artem Melnikov] (2025-10-22T08:56:55.140Z)\nassessment with the, well, with the assessment, the document, right? And then there was, he also instructed like the, the, the gradient agent to go through the links from the document and also get all that other content. So there are some assessments, for example, which have like the Google sheets and the Google sheets that they provide. I've seen some of them, they can be really huge, like really huge with a lot of data, right?\n\n When the agent will try to extract that the whole CSV from the sheet and we'll put it into the prompt, it can lead to a token count problem. So there are instruments around that. For example, we can say, okay, only like white list of the specific sheet names that you want to extract or black list, something that you don't want to see. But in general, well, this is something that also was present for the old grading.\n\n You can simply go over token count. So that was one problem. Another problem is the throttling. So now, well, we're kind of overall, on all our fronts, we're kind of sometimes hitting those limits in many services. And this is the similar situation for the grading board. So I'm using the SONET 4.5 because it's really good. It displayed much better capabilities and everything. So I'm using that one.\n\n But the limits on that are not that great and the problem is that let's say what they do in the dry run, right? They do in the dry run, so they pitch like, okay, let's say 30 ASRs, right? 30 ASRs and they have 10 grading rules So that would be 300 separate evaluations basically, they just put it into the system And 300 evaluations, each one of them can be like, you know, 20, 50k tokens and they just hit the backend at the same time which results in the throttling.\n\n So we have retries and trying to go around that. But in the end, the current system, it doesn't really have the capability to really handle that load gracefully, that spike. So right now, we hit a throttle, okay, we will retry some minutes and that's how it works right but it doesn't really so you start the grading like it's not a it's not a gradual back off or what you're saying you're saying yeah it's a it's a back off but uh it should be a queue probably no yes it should be a queue ideally it should be a queue we should monitor the available limits on the modules and then we should you know send next tasks so that that's kind of the technical problem did we ask it about to increase the limits?\n\n Last time we asked, and they replied us that they have issues with the capacity. And we are like, can you ask again?\n\n[Dragos Nuta] (2025-10-22T09:00:00.153Z)\nIf they're not doing that, we'll just hit Anthropic directly. If you don't want us to use Bedrock, we can just use Anthropic.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:00:07.978Z)\nYes, so I'm planning to.\n\n[Dragos Nuta] (2025-10-22T09:00:09.798Z)\nThe amount of volume we have, I don't think I can. Wait about AWS to increase infrastructure. Another question is, are we using those shared nodes instead of the dedicated nodes? Like there's that thing that I always forget the name of They can have different profiles.\n\n[Artem Melnikov] (2025-10-22T09:00:31.474Z)\nGlobal and regional profiles. Yes, something like that. Yeah, and they have different limits. So for the grading board, I think I'm using the global one because it wasn't used by anything else before, so all of its limits were not consumed. But I'm hitting the limits of that one as a single user right now, so that's...\n\n[Dragos Nuta] (2025-10-22T09:00:53.418Z)\nI think you should explain them what we need. Do you have access to the Philology Anthropic account?\n\n[Artem Melnikov] (2025-10-22T09:01:01.201Z)\nI think so, yeah. I'm not sure what is the level of it, but I have access.\n\n[Dragos Nuta] (2025-10-22T09:01:05.363Z)\nWhat I'm trying to say is the following. Let's see what the limits are on the Anthropic, on the other and potentially talk to Benny, Benny Deville, you guys have seen that email, he's from somewhere, and see if we have enough room for our need, and then tell it to Apple, it's like, I don't know, we just need this bike, if you can't do it, then I guess we'll just have to run the Antropic, to hit the Antropic endpoints.\n\n\n\n[Rezgar Cadro] (2025-10-22T09:01:28.825Z)\nBut I don't understand, why don't we actually just implement the queuing?\n\n[Dragos Nuta] (2025-10-22T09:01:34.189Z)\nThere is queuing, my understanding is that the queuing is there, it's just that Artemis is proposing a more intelligent solution that checks for the current level of throttling, so it doesn't even try if there is no...\n\n[Rezgar Cadro] (2025-10-22T09:01:48.044Z)\nAs far as I understood, there is no queuing.\n\n[Artem Melnikov] (2025-10-22T09:01:49.544Z)\nThe queue right now, well, yeah, the queue right now, we have the queue of the messages that runs the gradient. When we run the gradient, if we receive a throttle, we essentially say, okay, delay this message for the X amount of minutes, but put it back onto the queue, so it will retry after some time.\n\n[Rezgar Cadro] (2025-10-22T09:02:07.135Z)\nYes, there is a limit on the number of processed, like currency? No, the concurrency on the queue. So we like process five items at a time.\n\n[Artem Melnikov] (2025-10-22T09:02:16.400Z)\nYeah, there is a limitation on that, I think, but...\n\n[Rezgar Cadro] (2025-10-22T09:02:21.002Z)\nWe can just reduce it, right? So we don't run into throttling issues.\n\n[Artem Melnikov] (2025-10-22T09:02:26.605Z)\nYeah, I guess we can try that. I will need to Check. I remember there were some settings. I don't remember which one of them exactly, but the problem again right now, I mean, that's That's kind of the difference, right? So we can play with those parameters, but the problem is that the load is unexpected on different levels. So you can have a lot of the requests, but all of them might be a really small token amount.\n\n So you can actually evaluate all of them, right? But there can be a low amount of the requests, but the token account would be very huge. And so even with five, you can throw it. So it should be, that's why I think if we need to implement something it should be intelligent in a sense that it would understand what are the requirements for every kind of this evaluation request and how it should organize them so that we would process them.\n\n\n\n[Rezgar Cadro] (2025-10-22T09:03:18.847Z)\nWe're not running real-time workflows. It would be just much simpler if we just have this queue with a small enough concurrency limit and then it just processes like five minutes later.\n\n[Artem Melnikov] (2025-10-22T09:03:31.170Z)\nWho cares?\n\n[Artem Melnikov] (2025-10-22T09:03:33.220Z)\nThe problem is that it's nice if it's like 3-5 minutes, but then right now we had a situation, well, not right now, but we had a situation where it's like 40 later, because you are doing the first invocation, it retries, the second, the back-off increases, and then you're hitting the last retry, and it's increasing even more, so 40 minutes, and the hardware manager says, okay, I started this dry run 40 minutes ago, and it's still running, what's going on, is it stuck, or is there an error, and that's what we had, right?\n\n So that's the problem here. When you use non-intelligent systems, you receive a non-intelligent outcome. So we're playing with the parameters, and we're trying to improve it, but there are limitations on what you can achieve with that. That's what I'm talking about.\n\n[Rezgar Cadro] (2025-10-22T09:04:25.193Z)\nOkay, so we have all the pieces is in place and we are just now trying to increase the throughput.\n\n[Dragos Nuta] (2025-10-22T09:04:37.427Z)\nBut the thing with counting tokens and seeing how much we can dynamically do, I'm not sure if I think...\n\n[Artem Melnikov] (2025-10-22T09:04:46.271Z)\nI do not plan to do that. I think that is something that would be nice to have, but this is not on the list of my priority at all. So I plan to improve the communication of the, first of all, we need to improve the communication of like, if there is a token error, if we expect to retry, we should communicate it better to the hiring managers. The email now provides a link to observe the status of the dry run.\n\n So they can navigate the link and it will tell how many jobs have been processed, how many still in the queue. I just plan to improve it even more to say, okay, this is like, is creating with token limit, it probably will be retried in like five minutes, so they would have better understanding on that front. And yeah, the token limit, and then basically there are a number of enhancements that I plan to do to counter that problem with the tokens that we have right now.\n\n And yeah, the issue with the explicit prompting, I guess that is I'm just trying to improve with the user guide.\n\n[Dragos Nuta] (2025-10-22T09:06:06.478Z)\nWhat else is going on at this moment? I think, Rezgar, you're going to start on the stage swapping. So keep your hands dirty. With the bubbles of the system?\n\n[Rezgar Cadro] (2025-10-22T09:06:21.356Z)\nFrom my analysis so far, let me share my screen maybe. So far, from what I understand, there are three components to this change. First of them, moving fraud Check before offer for all pipelines. It seems to be fairly easy from what I I and AI did the research for the code. It's updating like six flows, one trigger, a bunch of hardcodes, but nothing major, as well as some changes on the hardcodes and back and front and admin, but those are few.\n\n So this part should be simple enough to change. I don't know if it will be simple enough to test.\n\n[Dragos Nuta] (2025-10-22T09:07:13.670Z)\nThe second part with defining manuals or we keep greatest up for offline activities everything of Serbia. I was like, what's that?\n\n[Rezgar Cadro] (2025-10-22T09:08:10.945Z)\nYeah, yeah.\n\n[Rezgar Cadro] (2025-10-22T09:08:12.406Z)\nI think we use it in teach-tales to collect feedback from...\n\n[Dragos Nuta] (2025-10-22T09:08:15.708Z)\nOkay, got it.\n\n[Rezgar Cadro] (2025-10-22T09:08:19.291Z)\nI'm still figuring out everything that needs to be done here, but so far as I understand, everything is... Most of the stuff is already implemented, so we just... The subflow here and there doesn't seem that there is anything major.\n\n[Dragos Nuta] (2025-10-22T09:08:34.223Z)\nWe'll have to figure out how to distinguish applications. Step that don't require work, because there's no start button. It only tells you, hey, this is where you are. We are organizing your on-site interview.\n\n[Rezgar Cadro] (2025-10-22T09:08:51.158Z)\nIf it's waiting for grading, I understand that button shows up.\n\n[Dragos Nuta] (2025-10-22T09:08:55.960Z)\nYes, of course. But we need to create it. When you hit the stage, you need to know to create them in waiting for grading.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:09:05.734Z)\nto discuss it with them.\n\n[Dragos Nuta] (2025-10-22T09:09:06.414Z)\nI don't know if there's some flag already. Because if you bundle it into the fraud Check stage, then some will have actions and some will not have actions. If you create another stage, then maybe you can do it based on the stage. Like anything in that stage is created based on the stage. Yeah, I understand. That's why I'm asking. And look, it's worst case scenario, just some flag or something like that.\n\n Once the decision is made, I just want to understand how you'll do it, maybe.\n\n[Rezgar Cadro] (2025-10-22T09:09:43.599Z)\nAnd the last stage is adding a separate stage for screening. Again, from my research, it doesn't seem to be complex, especially since we will be changing a lot of that stuff, a lot of the same flows when we are switching fraud Check and offer places, so we might as well add a separate stage for that.\n\n[Dragos Nuta] (2025-10-22T09:10:08.566Z)\nIt makes more sense. I'm still not sure if it's to reuse the fraud Check.\n\n[Rezgar Cadro] (2025-10-22T09:10:20.812Z)\nOffline assessments is not really a fraud Check, right? Semantically at least.\n\n[Dragos Nuta] (2025-10-22T09:10:25.535Z)\nI think this stage is much better than reusing fraud Check.\n\n[Rezgar Cadro] (2025-10-22T09:10:29.952Z)\nI don't remember which one, but the screening seems to be.\n\n[Anirudh Bhardwaj] (2025-10-22T09:10:38.955Z)\nBut the only problem I was in cases where we don't have in-person interviews, right. The virtual interviews or the remote job interviews where after PCAD, we'll just give the offer. So how would we build that automation? Cause there will be some, we just skipped.\n\n[Rezgar Cadro] (2025-10-22T09:10:54.960Z)\nWe just skipped it. Just skip the stages which don't have any application steps?\n\n[Dragos Nuta] (2025-10-22T09:11:03.975Z)\nIt's empty. If you model steps, there's a config toggle. Now, how does this affect emails? That's another question. Because you need to tell something. If there are I think I'm pretty sure that the email that... I don't remember the email journey, but probably after you finish PCCat, when you get an email, which I'm very sure... Maybe you can share the document I shared with you yesterday, and it had all the emails as a sequence, and I can see that.\n\n But I'm pretty sure there's an email once you pass PCCat, and that email basically should have a component, or there should be two emails if you go into the finals. Versus if you don't. I think that's enough. I'm not into tailoring it. The only difference is that, hey, you're done. You're now about to get an offer or whatever it says versus your great job. I don't know. And then something that says, there are some further steps.\n\n Log into the portal to navigate this. I'm not asking for the emails to include the actual details from the application step. I don't think there's much value in that.\n\n[Rezgar Cadro] (2025-10-22T09:12:24.212Z)\nSo we want to keep it simple, just make phrasing generic, lead them to the UI.\n\n[Dragos Nuta] (2025-10-22T09:12:29.195Z)\nTheme also so that you can skip or enter.\n\n[Rezgar Cadro] (2025-10-22T09:12:33.017Z)\nBetter than conditioning.\n\n[Dragos Nuta] (2025-10-22T09:12:35.338Z)\nThe decision would be different if we're talking about early stage, for example, if this would be like branches in the BFQ and whatnot. Those are not people you can keep up with, so you better be super explanatory and optimize completion But these are late stage and they are already overly excited about the job and the candidate and the hiring manager. So I don't assume that any confusion there will lead to losing the candidate because they are already in direct contact.\n\n So I can slack off a bit and make it a bit more simple.\n\n[Rezgar Cadro] (2025-10-22T09:13:05.706Z)\nYeah, they just learned that they succeeded and they should move on. I think that's all they want to know at this point.\n\n[Dragos Nuta] (2025-10-22T09:13:11.610Z)\nYeah, exactly. Okay, so you're on that high level. What do you think? When do you think you'll have this?\n\n[Rezgar Cadro] (2025-10-22T09:13:20.019Z)\nI hope to have it by the end of the week, it seems. At least implement it. I'm not sure if test it and deploy it and all that. I haven't done that yet, but implementation-wise, it seems like one, two days.\n\n[Anirudh Bhardwaj] (2025-10-22T09:13:34.543Z)\nI think we just have to think about how do we roll this out. That was what we were discussing as well, right? The candidates that are already active in the pipeline. Will change for them, the applications that are active in the pipeline?\n\n[Dragos Nuta] (2025-10-22T09:13:52.938Z)\nThe rollout task needs to be defined. Yeah, sure. That's a different thing than the task. I think that the task is the task, and testing it and showing it works is a task. It will be another task that basically defines the requirements on what to do with these guys. And I don't think about it hard enough to realize if this is all automatic. Can just like rewire things and it just works or we need people to do some manual moving of people because those names that didn't do fraud Check and now fraud Check it was a very late stage now it's an early stage some have gotten an offer you don't want to get on the offer again like I can imagine some mess there now on the bright side I don't think you have a lot of cases like that usually it's going to be like five candidates at a time that are in those in between those stages and you're throwing in a number.\n\n So even if you tell people, if you circulate with the hiring manager, tell them, hey, you have these five candidates that due to the stage thing, you'll have to manually manage them as they transition and blah, blah, blah. Here's the explanation. That's fine. I don't think you can do it by automatic. I definitely don't imagine an automatic mechanism that says, oh, these were started on the wrong or the old flow, so let's handle them in some different way.\n\n It's like a...\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:15:06.416Z)\nCommunication things.\n\n[Dragos Nuta] (2025-10-22T09:15:07.856Z)\nYeah, which is probably just a with Isabel or builders.\n\n[Anirudh Bhardwaj] (2025-10-22T09:15:12.750Z)\nGot it. Also, one more thing, since we were doing this particular, basically, we are restructuring the pipelines or swapping the stages for enabling the capabilities to do 1000 in education in 2026, right, that is our eventual goal. But it is still has that manual step of FBI Check in our system, it still would require some manual intervention from the pipeline managers and hiring managers. So once we are done with this, should we?\n\n\n\n[Dragos Nuta] (2025-10-22T09:15:45.204Z)\nNo, no, no, pipelines, keeping track of all the guys somewhere else. And now you're left with some amount of manual work, which is those you hire, you trigger the checks. And my understanding is those checks are very, a lot. Like if you're hiring in California, it's very different from if you're hiring in Texas or if you're hiring to Chicago or whatnot. So I want to take the complexity now when I don't even know it and it's perceived as a customer responsibility.\n\n Let them complain. Let that be the problem that... They're like, oh, I wasn't aware of that. Let's fix it. If we fix this too, I'm fine. I'm more than fine. If we do early next week, we do low bar grading. I don't know, mid next week, because you need to wire whatever VTOS and whatnot. If by mid next week, we have the flows and the low bar grading, I'm relaxed. Can we do full grading? But I expect that the back and force will take time.\n\n And I expect it will be like, OK, so we have an update. Let's run again on the 50. Oh, still 80% or still 90%. Here's some insight. Let's think some more. Here's some more inputs from you. We'll just take it one step at a time. My worry on AI grading of that video, or not my worry, my important curious question is, and I'd like to get an answer, once the answer is certain, is what's the thing that, what's our challenge?\n\n Our challenge is that the LLM is not listening. Our challenge is that we don't know what we're looking for. Or our challenge is that the LLM is missing certain capabilities in handling certain types of inputs. Like maybe it's video analysis cannot trigger certain things, or maybe it cannot distinguish sound beyond transcription, inflections and pauses and whatnot. What's the problem, right? Because if you're doing this like running with blinders and saying, I'm running this point, it doesn't work, then we won't know what limits are we hitting.\n\n And if we're, for example, realizing, that's my hunch at least, right? Actually, I'm not very sure at this point, but I can bet you that one month to one quarter, half a year ago, it didn't seem to me that models can pick up voice inflections. I don't know if that's the case today. And if they can't do it, then I'd rather say that and not use rules that rely on that as an engaging thing, because it would be like just flip a coin and get the result, pass, fail, and use something else instead.\n\n And say, OK, how about we use something else? Actually, I don't know what else to use. Maybe we use the timing in between phrasing. Or maybe we don't use anything. We just tell the hiring managers, We cannot match for that. What do you prefer? Keep doing mean bar grading, or you just don't rely on that and you'll figure it out yourself at final interview stage? I think the mental model I'm applying is turn unknown unknowns into known unknowns, if you guys know what I mean.\n\n What worries me is the things that I don't even know I don't know. But OK, so I guess the backlog is kind of scarce. So I need to do some work. Definitely, I'd like to have an API that returns the R2. I was chatting with the old builder. The R2, I added the comment. So we can chat about that. We can add the, yeah. Let me see. I don't think there are other points from me. I know there's a backlog that's not very rich, and that's on me.\n\n And Anirudh. But otherwise, any other things you guys want to tackle?\n\n[Rezgar Cadro] (2025-10-22T09:19:57.430Z)\nJust a brief question on the AI grader. So what I understand currently, we ask it a question. We provide it with a submission. And it doesn't return us the result. It just calls a bunch of tools. And some of them said pass-fail. Another one said numerical value for score, just at its own discretion. And this stuff is not validated at all, so we don't Check if the question we asked him or this type of submission that we provided him matches what he actually did with the result, right?\n\n And my suggestion was to add some validation there so that, you know, at least we know that if we ask him a score question, he doesn't answer with pass-fail. Does that make sense to you, Artem?\n\n[Artem Melnikov] (2025-10-22T09:20:44.285Z)\nYeah, we can do that. I've added these two there. Prompt level right now, so it is instructed to track the input types, and it now knows what is expected to provide without explicit input from the gradient rule, and in case if it does not have enough information how to understand how to get a numeric value if it is expected to provide that, it is instructed to request that and provide the reasoning saying that, okay, I don't know how to to how to assign a score, please give me more instructions.\n\n So I Read that thing. I'm not sure if it's past QC or not. I will Check. So this is the one that I'm adding. We can, I guess we can try to add like a hard guard layer, guard rails, where we just directly Check the output types if we really need that. I guess we can do that as well. I'm not sure, just show it.\n\n[Dragos Nuta] (2025-10-22T09:21:40.887Z)\nMy suggestion is the following, and I'm not picking on this because I think we want to open up. At some point, you reach a point where you can be busy improving something forever. The question is if it's still worth improving. What I know for sure is that the method that Ariut applied on the matching interview works best. Do retrospective. Every one week, spend the time to look over all work done during the last week.\n\n Or if you're very worried, do it daily. That will teach you definitely what you need to do instead of guessing. My tolerance to failure is... I have tolerance to failure. I know it's pieces of candidates, but we can be polite. We can get Isabel to send an apology message and whatnot. We can do something about it. It's not the ideal state, but we can do that. What I cannot forgive us is not looking at those things and saying, I don't think it might have any issues, but nobody told me, so I'm relaxed.\n\n That's the thing I don't want to happen. But otherwise, I'm torn to saying, So we pissed off a customer as long as we find it out and we are able to do something about it.\n\n[Rezgar Cadro] (2025-10-22T09:22:45.866Z)\nThat's a technical issue. It's not really about the customer. It's just...\n\n[Dragos Nuta] (2025-10-22T09:22:51.067Z)\nIt's a principle, not particular to your... Maybe the change you're saying needs to be done, maybe it doesn't. I don't know. You guys will make the decision. I'm just saying it's a principle. At some point you're like, should I do that or should I do not? Just think about the likelihood. And if you don't know the likelihood, you can definitely let it there as long as you look for it. Carve out some time regularly, and then improve based on actual data.\n\n I don't imagine myself being mad about, oh, we didn't improve that. We didn't know if it actually worked, but we caught it one day later or two days later, and we informed the customer. I think that's a manageable outcome. That's what I'm saying. That's the principle, again, not to this particular role. OK, so Artem, what would you be working And by the way, what's your timeline now?\n\n[Artem Melnikov] (2025-10-22T09:23:40.874Z)\nI don't know. I will have a call with Sherbert tomorrow. I guess we will know the finals there. So right now there are two basically issues, well not issues, tasks. So there is some issue with the Linkaging Analytics Expert that I noticed. I work on that ticket.\n\n[Dragos Nuta] (2025-10-22T09:23:59.585Z)\nBy the way, Ismabel told me that the whole publishing got stuck.\n\n[Artem Melnikov] (2025-10-22T09:24:03.367Z)\nYes, I already unblocked here this morning.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:24:07.338Z)\nWhat was the problem?\n\n[Artem Melnikov] (2025-10-22T09:24:09.259Z)\nIt is also related to the problem with the analytics. So the state of some campaigns was not expected. It wasn't transitioned to, didn't transition to the... Well, so the campaigns are initially created and planned. Yeah, and I discovered that there was like a separate scheduled Apex code that was like querying LinkedIn API to get the listed campaigns, update the status, and that didn't have the contract ID updated, because I didn't know about that part.\n\n So I updated it now, and I'm checking it to see that it should work or not.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:24:48.527Z)\nOh, that's like a one-week-old issue. Yeah, yeah, one-week-old.\n\n[Rezgar Cadro] (2025-10-22T09:24:53.910Z)\nI can only imagine diagnosing this without your context.\n\n[Dragos Nuta] (2025-10-22T09:24:59.512Z)\nI'm here. Like what Artem just told me, When I saw the problem yesterday and what I did in the lazy way, because she only sent me an error message, I moved that campaign from plan to started just to unblock her. But I was thinking like, if there's more than one, if there's one, maybe it's a glitch and glitches happen. If there's more than one, then something in the easy apply thing is broken. So I would have, I think I would have picked it too.\n\n But anyway, well, here's the way I think about it. Our time is not going away. Like when I, when I, when I, when I told Serban that when I was discussing with Serban and being like well not I think rather than rather than um rather than my suggestion was rather than trying to stay until I don't know you guys feel ready I would rather like make the change knowing that you can always get one hour per day or throws the problem yeah but when I link it in topic I noticed that there are lots of different APIs they now have, like the contract API or something.\n\n\n\n[Artem Melnikov] (2025-10-22T09:26:04.810Z)\nBasically, it's like the disposition thing for the Indeed. And I think it's similar to EasyApply, but a bit different. So they're introducing all that new stuff that we haven't looked at for a long time. And maybe we should consider if we want to.\n\n[Dragos Nuta] (2025-10-22T09:26:22.161Z)\nHere's what I'll ask you, if you look there and you can spend another one hour on it, tell me what APIs, we would have access because they have that thing where you create an API key and tell you what you can select. See the ones we have access and just create a list of the ones that are interesting and we have access and the ones that are interesting, we don't have access.\n\n[Artem Melnikov] (2025-10-22T09:26:41.400Z)\nWe have no access to anything interesting at all.\n\n[Dragos Nuta] (2025-10-22T09:26:43.761Z)\nI can't assume that. I can't assume that. And I've been hammering them for one month or one year on that and their response tended to be until now something like you're too small.\n\n[Artem Melnikov] (2025-10-22T09:26:54.026Z)\nOkay, I see.\n\n[Dragos Nuta] (2025-10-22T09:26:56.755Z)\nNot too small to give you access, but more like these are new features. Our enablement team is working directly with customers to make them successful. We have a long queue of customers. We're going through them and you're not at the top.\n\n[Dragos Nuta] (2025-10-22T09:27:09.625Z)\nYeah, okay.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:27:12.167Z)\nI will make a list.\n\n[Dragos Nuta] (2025-10-22T09:27:13.268Z)\nYeah, small. And I'm like, okay, then we're not at the top. I'll spend more money with another vendor, right? These are just like power relationships that don't always work. Okay, so what are you working on now?\n\n[Artem Melnikov] (2025-10-22T09:27:30.382Z)\nYeah, so that LinkedIn thing, I plan to fix it soon, and then I will move on to improve the grading board, like the stuff we discussed right now.\n\n[Dragos Nuta] (2025-10-22T09:27:38.066Z)\nOkay, and that's because you want predictability from hiring managers, right, you're saying?\n\n[Artem Melnikov] (2025-10-22T09:27:45.489Z)\nYeah, yeah, yeah, yeah. Well, I want them to understand what's going on, and not just, you know, posting into the chat Yeah, you want to get rid of the interruptions.\n\n[Dragos Nuta] (2025-10-22T09:27:55.662Z)\nI don't love the feature, but I love getting rid of interruptions. That's what I do love. I guess that's all.\n\n[Anirudh Bhardwaj] (2025-10-22T09:28:09.292Z)\nOne more thing. The org builders are saying, well, asking that we should move these grading to brain lifts and all those things. So right now, we have prompt-based. Grading, right, Artem, and we should, we will be part of moving it to BrainLift. Dragos, should we all pick that as well along with it?\n\n[Dragos Nuta] (2025-10-22T09:28:31.707Z)\nIf we don't do it when we did the version number two, I would not do it right now. I would see what's their problem. For example, I know for sure, at least as I heard from Artem, that there's a assessment grading context. So maybe that's the freaking BrainLift, just put it there. You still define the rules one by one. And I'm telling you why the rules still matter. Because having traceability on rule-based pass rates and whatnot is important.\n\n Guess what? We did the R2 simplification where it picks the min-par requirements for the interview bot, reading for it from the R2, and it's easy for them. You don't have to go into data model, you don't have to add neurons, whatnot. What were they asking me? I don't know. I've seen a question from one of them. Can we get I'm like, well, we don't have an object called question. You can't get pass rate per question.\n\n We have to model that. How important is it? I don't know. Do I even care about that? You know?\n\n[Anirudh Bhardwaj] (2025-10-22T09:29:28.437Z)\nGot it.\n\n[Dragos Nuta] (2025-10-22T09:29:29.778Z)\nSo actually, that's a good, interesting question. If we would want to do question level pass rate analysis for matching interviews, what would we do? Would we model the objects so that you have a requirement, and then there can be something like pass-fail, like the standard 2020s model? Or would we create an API that extracts everything at runtime and then gives you a CSV and runs an LLM on it, or something like that?\n\n\n\n[Aryuth Ekkul] (2025-10-22T09:30:03.781Z)\nI think having a concrete Models is the end goal, right?\n\n[Aryuth Ekkul] (2025-10-22T09:30:13.612Z)\nI mean, that is...\n\n[Dragos Nuta] (2025-10-22T09:30:15.973Z)\nI don't know, because when you add concrete, when you start adding an object called rule, you'll end up going to versioning. You'll go into, when did it change? You'll go into, is it the same or did you actually change the same ID? It doesn't strike me as solving a solution. It solves a solution from one angle. But if you change your angle a bit, it still affects the animal head. And whatnot.\n\n[Rezgar Cadro] (2025-10-22T09:30:37.688Z)\nIt depends on what we are going to do with this data.\n\n[Dragos Nuta] (2025-10-22T09:30:43.011Z)\nIn general, they want to assess the relevance of a rule, the reliability of a rule. They want to audit matching interviews. I think that's actually the question. How do you audit matching interviews? And I think that's why I was erring on the side of saying, you know what? What if we would hypothetically, and we're not doing that, expose endpoints? And one endpoint give me for an assessment all the summary.\n\n It tells like, hey, this candidate on this application, these rules, this question, that's the data. And then because it's an API, you can also say, OK, can you give me the full transcript of this candidate? What was asked and what was answered? Then they can manage everything. And maybe that's simpler, because then they can also have their own little Google Docs somewhere that says, oh, on that date, I changed those things in that Because I felt that if I do that, it will...\n\n Whatever. So analysis will be not just numerical, it will be in context.\n\n[Artem Melnikov] (2025-10-22T09:31:43.324Z)\nYeah, I think just giving those tools is nice, because when I did, for example, the synthesis of the gradient rules for the assessments, I basically took the submissions and then I took the gradient nodes for past 80 submissions, I just fed it to Cloud Code and ask it to analyze it and to understand why it happened, right? So if you just give it data in the raw form, it is now capable enough to do all those conclusions.\n\n And just answering the question, which gradient rule led to the most failures, it would be pretty simple for it, if it has the raw data.\n\n[Dragos Nuta] (2025-10-22T09:32:23.209Z)\nYou know, that's how they're using, I don't know whomever, some of them are using the APIs through Cloud Code today. They set up the... And they are just getting closed code. So that's why they asked to offer an R2 endpoint, and we'll talk about that Anirudh, because then they can assess it in the context of the R2. And another one was to probably offer a box somewhere on the pipeline with all builder nodes, where they can just list nodes, like a log.\n\n Hey, on that date, I did that. On that date, I did that. Because otherwise LLMs are providing it. Is there a way of influencing the way the LLM thinks about it?\n\n[Dragos Nuta] (2025-10-22T09:33:04.715Z)\nGot it.\n\n[Dragos Nuta] (2025-10-22T09:33:05.877Z)\nAnyway, conversation for another time. I need to drop now, but let's Check back a bit later. I'm going to continue the conversation on that.\n\n[Rezgar Cadro] (2025-10-22T09:33:20.684Z)\nBye, everyone.\n\n[UNKNOWN_SPEAKER] (2025-10-22T09:33:22.225Z)\nBye, guys."}